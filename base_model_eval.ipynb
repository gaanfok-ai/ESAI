{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import time\n",
    "import pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf4567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e26041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 2376, 1172)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openbookqa_test = load_dataset(\"allenai/openbookqa\", \"main\", split=\"test\")\n",
    "arc_easy_test = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\", split=\"test\")\n",
    "arc_chal_test = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\", split=\"test\")\n",
    "\n",
    "len(openbookqa_test), len(arc_easy_test), len(arc_chal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1571d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_openbookqa(ex):\n",
    "    # ex[\"choices\"] has \"label\" and \"text\"\n",
    "    labels = list(ex[\"choices\"][\"label\"])\n",
    "    choices = list(ex[\"choices\"][\"text\"])\n",
    "    answer_key = ex[\"answerKey\"]\n",
    "    return {\n",
    "        \"question\": ex[\"question_stem\"],\n",
    "        \"labels\": labels,\n",
    "        \"choices\": choices,\n",
    "        \"answer_key\": answer_key\n",
    "    }\n",
    "\n",
    "def norm_arc(ex):\n",
    "    # ex[\"choices\"] has \"label\" and \"text\" as lists\n",
    "    labels = list(ex[\"choices\"][\"label\"])\n",
    "    choices = list(ex[\"choices\"][\"text\"])\n",
    "    answer_key = ex[\"answerKey\"]\n",
    "    return {\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"labels\": labels,\n",
    "        \"choices\": choices,\n",
    "        \"answer_key\": answer_key\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e90aa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'choices': ['make more phone calls',\n",
       "   'quit eating lunch out',\n",
       "   'buy less with monopoly money',\n",
       "   'have lunch with friends'],\n",
       "  'question': 'A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to',\n",
       "  'labels': ['A', 'B', 'C', 'D'],\n",
       "  'answer_key': 'B'},\n",
       " {'question': 'Which statement best explains why photosynthesis is the foundation of most food webs?',\n",
       "  'choices': ['Sunlight is the source of energy for nearly all ecosystems.',\n",
       "   'Most ecosystems are found on land instead of in water.',\n",
       "   'Carbon dioxide is more available than other gases.',\n",
       "   'The producers in all ecosystems are plants.'],\n",
       "  'labels': ['A', 'B', 'C', 'D'],\n",
       "  'answer_key': 'A'},\n",
       " {'question': 'An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?',\n",
       "  'choices': ['Planetary density will decrease.',\n",
       "   'Planetary years will become longer.',\n",
       "   'Planetary days will become shorter.',\n",
       "   'Planetary gravity will become stronger.'],\n",
       "  'labels': ['A', 'B', 'C', 'D'],\n",
       "  'answer_key': 'C'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CANON = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "def canonicalize_labels(question, labels, choices, answer_key):\n",
    "    # map from original label -> canonical label by position\n",
    "    mapping = {orig: CANON[i] for i, orig in enumerate(labels)}\n",
    "    canon_labels = [mapping[l] for l in labels]\n",
    "    canon_answer = mapping[answer_key]\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"labels\": canon_labels,\n",
    "        \"choices\": choices,\n",
    "        \"answer_key\": canon_answer,\n",
    "    }\n",
    "\n",
    "def norm_openbookqa_canon(ex):\n",
    "    labels = list(ex[\"choices\"][\"label\"])\n",
    "    choices = list(ex[\"choices\"][\"text\"])\n",
    "    answer_key = ex[\"answerKey\"]\n",
    "    return canonicalize_labels(ex[\"question_stem\"], labels, choices, answer_key)\n",
    "\n",
    "def norm_arc_canon(ex):\n",
    "    labels = list(ex[\"choices\"][\"label\"])\n",
    "    choices = list(ex[\"choices\"][\"text\"])\n",
    "    answer_key = ex[\"answerKey\"]\n",
    "    return canonicalize_labels(ex[\"question\"], labels, choices, answer_key)\n",
    "\n",
    "openbookqa_norm = openbookqa_test.map(norm_openbookqa_canon, remove_columns=openbookqa_test.column_names)\n",
    "arc_easy_norm = arc_easy_test.map(norm_arc_canon, remove_columns=arc_easy_test.column_names)\n",
    "arc_chal_norm = arc_chal_test.map(norm_arc_canon, remove_columns=arc_chal_test.column_names)\n",
    "\n",
    "openbookqa_norm[0], arc_easy_norm[0], arc_chal_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5057c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00187414c40943f89e028654ed253b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "model.eval()\n",
    "if device == \"cpu\":\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d99fcd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 1112.93 MB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b45a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question, labels, choices):\n",
    "    # Ensure consistent ordering\n",
    "    opts = \"\\n\".join([f\"{l}. {c}\" for l, c in zip(labels, choices)])\n",
    "    user = (\n",
    "        \"Answer the multiple-choice question.\\n\"\n",
    "        \"Reply with exactly one line in this format:\\n\"\n",
    "        \"Final answer: <LETTER>\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Choices:\\n{opts}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that follows the format exactly.\"},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "    # Qwen2.5-Instruct supports chat template\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de317591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openbookqa_test: 10 samples ===\n",
      "\n",
      "--- Sample 1 (idx=327) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: In the hottest months in the hottest desert, creatures such as birds may find water to drink\n",
      "Choices:\n",
      "A. in sticks\n",
      "B. in pebbles\n",
      "C. in sand\n",
      "D. in spiked plants\n",
      "\n",
      "assistant\n",
      "Final answer: C. in sand\n",
      "\n",
      "--- Sample 2 (idx=57) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A construction group wants to put a shopping center in town, but the only place available is a small nature park with a trail. Deer and other wildlife frequent the park, since it is the only place in the city where trees and fresh water are available for them. The construction group decides to build the shopping center, which means that\n",
      "Choices:\n",
      "A. the deer are moved to a zoo\n",
      "B. the trail is expanded\n",
      "C. the mall has a nature park in it\n",
      "D. the wildlife environment is destroyed\n",
      "\n",
      "assistant\n",
      "Final answer: D\n",
      "\n",
      "--- Sample 3 (idx=12) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A red-tailed hawk is searching for prey. It is most likely to swoop down on\n",
      "Choices:\n",
      "A. an eagle\n",
      "B. a cow\n",
      "C. a gecko\n",
      "D. a deer\n",
      "\n",
      "assistant\n",
      "Final answer: D\n",
      "\n",
      "--- Sample 4 (idx=379) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which animal is hiding from a predator?\n",
      "Choices:\n",
      "A. a tadpole losing its tail as it grows\n",
      "B. an angler fish using its Esca to lure another fish\n",
      "C. an octopus mimicking the color and texture of a rocky outcrop\n",
      "D. a great white shark breaching the water's surface\n",
      "\n",
      "assistant\n",
      "Final answer: C\n",
      "\n",
      "--- Sample 5 (idx=140) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: It takes more water to fill a bathtub than a\n",
      "Choices:\n",
      "A. lake\n",
      "B. pool\n",
      "C. stomach\n",
      "D. holding tank\n",
      "\n",
      "assistant\n",
      "Final answer: A\n",
      "\n",
      "--- Sample 6 (idx=125) ---\n",
      "GOLD: A\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Since density = mass / volume, denser liquids such as water sink more than\n",
      "Choices:\n",
      "A. baby oil\n",
      "B. corn syrup or\n",
      "C. milk\n",
      "D. honey\n",
      "\n",
      "assistant\n",
      "Final answer: B\n",
      "\n",
      "--- Sample 7 (idx=114) ---\n",
      "GOLD: A\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: What may have been formed by a volcano?\n",
      "Choices:\n",
      "A. Mt. McKinley\n",
      "B. Lake Pontchartrain\n",
      "C. The great lakes\n",
      "D. Niagara Falls\n",
      "\n",
      "assistant\n",
      "Final answer: B\n",
      "\n",
      "--- Sample 8 (idx=71) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Decaying vegetation is part of the process that\n",
      "Choices:\n",
      "A. enables nuclear power to function\n",
      "B. enables to emitting of light beams\n",
      "C. enables gas powered motors to operate\n",
      "D. enables windmills to power electric grids\n",
      "\n",
      "assistant\n",
      "Decaying vegetation is part of the process that:\n",
      "\n",
      "\n",
      "\n",
      "--- Sample 9 (idx=377) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: After a storm\n",
      "Choices:\n",
      "A. ponds may dry out\n",
      "B. flowers will wilt and wither\n",
      "C. creek beds may be spilling over\n",
      "D. drinking water will be in short supply\n",
      "\n",
      "assistant\n",
      "After a storm, it's likely that:\n",
      "\n",
      "Final\n",
      "\n",
      "--- Sample 10 (idx=52) ---\n",
      "GOLD: A\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Overpopulation of an organism can\n",
      "Choices:\n",
      "A. strain the resources of an ecosystem\n",
      "B. cause boundless growth of resources\n",
      "C. lead to extinction of the organism\n",
      "D. cause the ecosystem to flourish\n",
      "\n",
      "assistant\n",
      "Final answer: A\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(prompt, max_new_tokens=10):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,          # deterministic\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    # Return only the tail after the prompt where possible\n",
    "    return text\n",
    "\n",
    "def sample_and_print(ds, n=10, name=\"dataset\"):\n",
    "    idxs = random.sample(range(len(ds)), n)\n",
    "    print(f\"=== {name}: {n} samples ===\")\n",
    "    for i, idx in enumerate(idxs, 1):\n",
    "        ex = ds[idx]\n",
    "        prompt = build_prompt(ex[\"question\"], ex[\"labels\"], ex[\"choices\"])\n",
    "        full = generate_text(prompt)\n",
    "        print(f\"\\n--- Sample {i} (idx={idx}) ---\")\n",
    "        print(\"GOLD:\", ex[\"answer_key\"])\n",
    "        print(full[-800:])  # print last chunk (includes model answer)\n",
    "\n",
    "sample_and_print(openbookqa_norm, n=10, name=\"openbookqa_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9a5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== arc_easy_test: 10 samples ===\n",
      "\n",
      "--- Sample 1 (idx=2233) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A student has decided to investigate whether the number of flowers on a plant will increase if the water supply to the plant is increased. She has five pots of geranium plants to use in her experiment. What factor in the experiment should be varied for the five plants in order to answer the student's question?\n",
      "Choices:\n",
      "A. age of seedlings\n",
      "B. temperature of water\n",
      "C. volume of water\n",
      "D. number of hours in sunlight\n",
      "\n",
      "assistant\n",
      "Final answer: C. Volume of water\n",
      "\n",
      "--- Sample 2 (idx=356) ---\n",
      "GOLD: A\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Eating food that is undercooked can lead to a disease that affects the digestive system. Which body part is directly affected by the disease?\n",
      "Choices:\n",
      "A. intestines\n",
      "B. arteries\n",
      "C. nerves\n",
      "D. sinuses\n",
      "\n",
      "assistant\n",
      "Final answer: A. intestines\n",
      "\n",
      "--- Sample 3 (idx=1728) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: India was once its own continent. According to the theory of continental drift, India has collided with and become part of the continent of Asia. This caused\n",
      "Choices:\n",
      "A. glaciers in the area to melt.\n",
      "B. large mountain ranges to form.\n",
      "C. deep mid-ocean trenches to develop.\n",
      "D. deserts in the area to become fertile.\n",
      "\n",
      "assistant\n",
      "Final answer: B\n",
      "\n",
      "--- Sample 4 (idx=130) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: What characteristic of carbon [C] makes it essential to living organisms?\n",
      "Choices:\n",
      "A. Carbon forms crystal structures under certain conditions.\n",
      "B. Carbon can exist as a solid, liquid, or gas.\n",
      "C. Carbon bonds in many ways with itself to form chains.\n",
      "D. Carbon exists in radioactive forms.\n",
      "\n",
      "assistant\n",
      "Final answer: C. Carbon bonds in many ways\n",
      "\n",
      "--- Sample 5 (idx=122) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: What is the primary reason for breaking down food molecules?\n",
      "Choices:\n",
      "A. to absorb water into a cell\n",
      "B. to provide energy for a cell\n",
      "C. to remove wastes from a cell\n",
      "D. to store materials in a cell\n",
      "\n",
      "assistant\n",
      "Final answer: B. to provide energy for a\n",
      "\n",
      "--- Sample 6 (idx=383) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which is the most important reason for scientists to publish their data and findings that result from a scientific investigation?\n",
      "Choices:\n",
      "A. to become famous\n",
      "B. to get paid for their research\n",
      "C. to allow other scientists to try to replicate their results\n",
      "D. to gain respect from their peers in the scientific community\n",
      "\n",
      "assistant\n",
      "Final answer: C. to allow other scientists to\n",
      "\n",
      "--- Sample 7 (idx=895) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which of these must occur when a substance goes through a chemical change?\n",
      "Choices:\n",
      "A. The substance gets larger.\n",
      "B. The substance changes phases.\n",
      "C. The substance changes shape.\n",
      "D. The substance forms a new substance.\n",
      "\n",
      "assistant\n",
      "D. The substance forms a new substance.\n",
      "\n",
      "--- Sample 8 (idx=952) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which food contains the highest percentage of protein?\n",
      "Choices:\n",
      "A. rice\n",
      "B. dates\n",
      "C. carrots\n",
      "D. chicken\n",
      "\n",
      "assistant\n",
      "Final answer: D. chicken\n",
      "\n",
      "--- Sample 9 (idx=2069) ---\n",
      "GOLD: A\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which would be best seen through a telescope?\n",
      "Choices:\n",
      "A. a moon\n",
      "B. a cell\n",
      "C. a light ray\n",
      "D. a molecule\n",
      "\n",
      "assistant\n",
      "Final answer: A. a moon\n",
      "\n",
      "--- Sample 10 (idx=108) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Over time, dried lava from an old volcano is worn down and broken into small pieces. When these pieces pile up and are cemented together to form new rock, how would this new rock be classified?\n",
      "Choices:\n",
      "A. magma\n",
      "B. igneous\n",
      "C. sedimentary\n",
      "D. metamorphic\n",
      "\n",
      "assistant\n",
      "Final answer: C.\n"
     ]
    }
   ],
   "source": [
    "sample_and_print(arc_easy_norm, n=10, name=\"arc_easy_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e71c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== arc_challenge_test: 10 samples ===\n",
      "\n",
      "--- Sample 1 (idx=1149) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A hot rock is dropped into a pail of cool water. Heat energy transferred from the rock to the water by\n",
      "Choices:\n",
      "A. boiling.\n",
      "B. evaporation.\n",
      "C. conduction.\n",
      "D. radiation.\n",
      "\n",
      "assistant\n",
      "Final answer: C. conduction.\n",
      "\n",
      "--- Sample 2 (idx=407) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A science student notices that the contents of one of the test tubes in an experiment are bubbling and changing colors. Before completing the experiment, the student records that the substance in this particular test tube is undergoing a chemical change. The student's statement is an example of\n",
      "Choices:\n",
      "A. an observation.\n",
      "B. a hypothesis.\n",
      "C. a conclusion.\n",
      "D. an inference.\n",
      "\n",
      "assistant\n",
      "Final answer: D.\n",
      "\n",
      "--- Sample 3 (idx=1116) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which tool would be the most helpful in an investigation of the life cycle of a monarch butterfly?\n",
      "Choices:\n",
      "A. a sharp knife\n",
      "B. a magnifying glass\n",
      "C. a long piece of string\n",
      "D. a large jar with air holes in the top\n",
      "\n",
      "assistant\n",
      "Final answer: D.\n",
      "\n",
      "--- Sample 4 (idx=859) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: David makes a solution by dissolving 10 grams of salt in 100 ml of water. He wants a solution that is half as concentrated. What should he add to the original solution to obtain a solution that is about half as concentrated?\n",
      "Choices:\n",
      "A. 50 ml of water\n",
      "B. 100 ml of water\n",
      "C. 5 grams of salt\n",
      "D. 10 grams of salt\n",
      "\n",
      "assistant\n",
      "Final answer: C. 5 grams of salt\n",
      "\n",
      "--- Sample 5 (idx=451) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Which adaptation helps a worm move in soil?\n",
      "Choices:\n",
      "A. moist skin\n",
      "B. tube-like body\n",
      "C. skin that breathes\n",
      "D. very small mouth\n",
      "\n",
      "assistant\n",
      "Final answer: B\n",
      "\n",
      "--- Sample 6 (idx=919) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: If two tectonic plates are each moving in opposite directions away from the mid-ocean ridge at a rate of 10 millimeters per year, how long will it take for the ridge to become 100 millimeters broader?\n",
      "Choices:\n",
      "A. 1 year\n",
      "B. 5 years\n",
      "C. 10 years\n",
      "D. 100 years\n",
      "\n",
      "assistant\n",
      "Final answer: C.\n",
      "\n",
      "--- Sample 7 (idx=569) ---\n",
      "GOLD: D\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A metal rod is struck and starts to vibrate. Which of these could happen next?\n",
      "Choices:\n",
      "A. The metal rod becomes a liquid.\n",
      "B. The metal rod becomes heavier.\n",
      "C. The metal rod attracts other metals.\n",
      "D. The metal rod produces sound.\n",
      "\n",
      "assistant\n",
      "Final answer: D\n",
      "\n",
      "--- Sample 8 (idx=13) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: A class plans an investigation to see which brand of light bulb lasts the longest. Which of these steps should come first?\n",
      "Choices:\n",
      "A. Repeat the investigation.\n",
      "B. Write a report of the results.\n",
      "C. Make a table for recording data.\n",
      "D. Make daily observations of the light bulbs.\n",
      "\n",
      "assistant\n",
      "Final answer: C\n",
      "\n",
      "--- Sample 9 (idx=326) ---\n",
      "GOLD: B\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: What is one condition necessary to produce diamonds?\n",
      "Choices:\n",
      "A. high altitude\n",
      "B. intense pressure\n",
      "C. quick cooling\n",
      "D. low temperatures\n",
      "\n",
      "assistant\n",
      "Final answer: B.\n",
      "\n",
      "--- Sample 10 (idx=865) ---\n",
      "GOLD: C\n",
      "system\n",
      "You are a helpful assistant that follows the format exactly.\n",
      "user\n",
      "Answer the multiple-choice question.\n",
      "Reply with exactly one line in this format:\n",
      "Final answer: <LETTER>\n",
      "\n",
      "Question: Some new cars use special braking systems to recover energy when the brakes are applied. This energy is stored in special batteries and is used to power the electric motor. What type of energy are the brakes storing as they slow down the car?\n",
      "Choices:\n",
      "A. gravitational\n",
      "B. kinetic\n",
      "C. potential\n",
      "D. thermal\n",
      "\n",
      "assistant\n",
      "Final answer: B. kinetic\n"
     ]
    }
   ],
   "source": [
    "sample_and_print(arc_chal_norm, n=10, name=\"arc_challenge_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35e5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_RE = re.compile(r\"\\b([A-D])\\b\")\n",
    "\n",
    "def extract_letter(text, valid_labels={\"A\",\"B\",\"C\",\"D\"}):\n",
    "    matches = [m.group(1) for m in ANSWER_RE.finditer(text)]\n",
    "    for label in reversed(matches):\n",
    "        if label in valid_labels:\n",
    "            return label\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8012114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openbookqa compliance: 1.0\n",
      "arc_easy compliance: 1.0\n",
      "arc_chal compliance: 1.0\n"
     ]
    }
   ],
   "source": [
    "def compliance_rate(ds, k=200):\n",
    "    idxs = random.sample(range(len(ds)), min(k, len(ds)))\n",
    "    ok = 0\n",
    "    for idx in idxs:\n",
    "        ex = ds[idx]\n",
    "        prompt = build_prompt(ex[\"question\"], ex[\"labels\"], ex[\"choices\"])\n",
    "        out = generate_text(prompt)\n",
    "        pred = extract_letter(out, set(ex[\"labels\"]))\n",
    "        ok += int(pred is not None)\n",
    "        if(pred is None):\n",
    "            print(out)\n",
    "    return ok / len(idxs)\n",
    "\n",
    "print(\"openbookqa compliance:\", compliance_rate(openbookqa_norm, 200))\n",
    "print(\"arc_easy compliance:\", compliance_rate(arc_easy_norm, 200))\n",
    "print(\"arc_chal compliance:\", compliance_rate(arc_chal_norm, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332c43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pynvml.nvmlInit()\n",
    "HANDLE = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def sample_power(handle):\n",
    "    # returns power in Watts\n",
    "    return pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0\n",
    "\n",
    "def evaluate(ds, sample_dt=0.1):\n",
    "    correct = 0\n",
    "    total = len(ds)\n",
    "\n",
    "    power_samples = []\n",
    "    t_start = time.time()\n",
    "    last_sample = t_start\n",
    "\n",
    "    for ex in ds:\n",
    "        now = time.time()\n",
    "        if now - last_sample >= sample_dt:\n",
    "            power_samples.append(sample_power(HANDLE))\n",
    "            last_sample = now\n",
    "\n",
    "        prompt = build_prompt(ex[\"question\"], ex[\"labels\"], ex[\"choices\"])\n",
    "        output = generate_text(prompt)\n",
    "        pred = extract_letter(output)\n",
    "\n",
    "        if pred == None:\n",
    "            print(output)\n",
    "        if pred == ex[\"answer_key\"]:\n",
    "            correct += 1\n",
    "\n",
    "    t_end = time.time()\n",
    "\n",
    "    # --- metrics ---\n",
    "    duration = t_end - t_start\n",
    "    avg_power = sum(power_samples) / len(power_samples)\n",
    "    energy_joules = avg_power * duration\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct / total,\n",
    "        \"time_sec\": duration,\n",
    "        \"avg_power_w\": avg_power,\n",
    "        \"energy_j\": energy_joules,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20125a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.71,\n",
       " 'time_sec': 113.80131030082703,\n",
       " 'avg_power_w': 63.08438476953908,\n",
       " 'energy_j': 7179.085646295083}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_obqa = evaluate(openbookqa_norm)\n",
    "acc_obqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1079b8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.851010101010101,\n",
       " 'time_sec': 555.2197864055634,\n",
       " 'avg_power_w': 64.26668030366933,\n",
       " 'energy_j': 35682.13251119791}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_arc_easy = evaluate(arc_easy_norm)\n",
    "acc_arc_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fe3429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6766211604095563,\n",
       " 'time_sec': 273.0134959220886,\n",
       " 'avg_power_w': 64.8860247863248,\n",
       " 'energy_j': 17714.760463401824}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_arc_challenge = evaluate(arc_chal_norm)\n",
    "acc_arc_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "  --model hf \\\n",
    "  --model_args pretrained=Qwen/Qwen2.5-1.5B-Instruct,dtype=auto,device_map=auto \\\n",
    "  --tasks openbookqa,arc_easy,arc_challenge \\\n",
    "  --batch_size auto \\\n",
    "  --num_fewshot 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030335b",
   "metadata": {},
   "source": [
    "|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
    "|-------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
    "|arc_challenge|      1|none  |     0|acc     |↑  |0.4352|±  |0.0145|\n",
    "|             |       |none  |     0|acc_norm|↑  |0.4676|±  |0.0146|\n",
    "|arc_easy     |      1|none  |     0|acc     |↑  |0.7664|±  |0.0087|\n",
    "|             |       |none  |     0|acc_norm|↑  |0.7614|±  |0.0087|\n",
    "|openbookqa   |      1|none  |     0|acc     |↑  |0.3160|±  |0.0208|\n",
    "|             |       |none  |     0|acc_norm|↑  |0.4080|±  |0.0220|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinkslm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
